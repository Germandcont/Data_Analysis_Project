{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan de reparado de datos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escalado\n",
    "\n",
    "- Conversions <br/>\n",
    "\n",
    "(Núnero de acciones exitosas, como compras o registros) Tiene un máximo de 6000 y un mínimo de 13  <br/>\n",
    "Quizás para reparar los datos sería una buena idea ya que hay muchas variables que influirán en la cantidad de conversiones.  <br/>\n",
    "Inversion <br/>\n",
    "Registros o compras?  <br/>\n",
    "Tamaño de la empresa <br/>\n",
    "Calidad del producto en cuestión \n",
    "\n",
    "Todas estas cosas podrían hacer que dos campañas no sean comparabales, una campaña podría ser positiva con un total de 13 ventas al igual que otra con 6000\n",
    "\n",
    "La tasa de conversión por ejemplo no podría escalarla porque ya esta calculada a partir de otra cosa, como por ejemplo cuantos entraron a una tienda vs cuantos compraron algo (Impressions vs Conversions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clicks <br/>\n",
    "\n",
    "Esto podría escalarlo tambien ya que depende de muchos factores al igual que las conversions y existe mucha diferencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Impressions <br/>\n",
    "\n",
    "Tambien existe demasiada diferencia entre el valor max y el min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESTO SERIA PARA PODER REPARAR LOS DATOS FALTANTES A TRAVÉS DE LA MEDIA Y QUE ESTA NO SE VEA TAN ALTERADA POR LA DIFERENCIA TAN GRANDE QUE HAY EN ALGUNAS VARIABLES\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df2[''] = scaler.fit_transform(df2[['']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparamos por su mean las columnas \n",
    "df2[''].fillna(df2[''].mean()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos escalar los datos antes de hacer una predicción con encoding (KNN) \n",
    "\n",
    "Por ejemplo en el caso de los clicks, puedo escalarlos y luego estos me van a servir para que la predicción realizada sea mejor, si tengo una campaña que me genero 1.000.000 de clicks y otras 10 cicks, al momento de analizar los vecinos con el knn puedo tener errores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENCODING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el Onehotencoder para reparar las variables de tipo objeto\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos las columnas que vamos a encodear\n",
    "\n",
    "columnas = [\"x\", \"y\", \"z\"]\n",
    "\n",
    "#Encoding \n",
    "encoder = OneHotEncoder()\n",
    "encoded_array = encoder.fit_transform(df[columnas]).toarray()\n",
    "df_encoder = pd.DataFrame(encoded_array)\n",
    "df_encoder.columns = encoder.get_feature_names_out(columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A mi tabla encodeada le traigo los valores originales de x, como en el ejemplo de titanic donde queriamos tener los valores de \"age\" dentro del data frame encodeado para realizar la reparación\n",
    "df_encoder[\"age\"] = df[\"age\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debo crear dos dataframe basandome en el dato que quiero reparar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_age = df_encoder.dropna(subset=['age']) # Entro a mi df_encoder y elimino todas las columnas que no sean \"age\"\n",
    "df_without_age = df_encoder[df_encoder['age'].isna().drop(columns='age')] # Hago lo contrario, toma todas las columnas menos la de \"age\"\n",
    "\n",
    "# La tabla sin \"age\" serán valores encodeados y la otra no ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos el dataframe para que una parte sea de testing y otra de training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_with_age.drop(columns='age'), df_with_age['age'], test_size=0.2, random_state=357)\n",
    "\n",
    "#Random state es una semilla para saber desde que punto vamos a empezar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
